<!DOCTYPE html>
<html lang="zh-Hans">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="刘小恺" />



<meta name="description" content="1.模型表示问题的概述 在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子。">
<meta name="keywords" content="机器学习,梯度下降">
<meta property="og:type" content="article">
<meta property="og:title" content="线型回归 &amp; 梯度下降">
<meta property="og:url" content="http://blog.kyleliu.cn/2018/10/20/10.机器学习/基础内容/线型回归/index.html">
<meta property="og:site_name" content="刘小恺(Kyle) 的个人博客">
<meta property="og:description" content="1.模型表示问题的概述 在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1539965168129.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1539965299259.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1539965543172.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1539965938888.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540021643524.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540029941521.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540022174651.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540024168426.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540026766508.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540568088758.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540042706219.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540028773553.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540028837422.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540028905489.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540563412916.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540635502085.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540566461561.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540566614915.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540616820528.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540616493267.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540567672941.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540644955305.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540645069496.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540619927547.png">
<meta property="og:image" content="http://blog.kyleliu.cn/img/1540620250525.png">
<meta property="og:updated_time" content="2018-10-28T11:43:48.947Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="线型回归 &amp; 梯度下降">
<meta name="twitter:description" content="1.模型表示问题的概述 在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子。">
<meta name="twitter:image" content="http://blog.kyleliu.cn/img/1539965168129.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="刘小恺(Kyle) 的个人博客" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>线型回归 &amp; 梯度下降 | 刘小恺(Kyle) 的个人博客</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: 
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">刘小恺</a></h1>
        </hgroup>

        
        <p class="header-subtitle">Python 、  Machine learning 、 Docker、 爬虫</p>
        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:123@123.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/">Docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/octave/">octave</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/博客/">博客</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/梯度下降/">梯度下降</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">专注于前端</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">刘小恺</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">刘小恺</a></h1>
            </hgroup>
            
            <p class="header-subtitle">Python 、  Machine learning 、 Docker、 爬虫</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:123@123.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="post-10.机器学习/基础内容/线型回归" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/10/20/10.机器学习/基础内容/线型回归/" class="article-date">
      <time datetime="2018-10-19T16:01:00.000Z" itemprop="datePublished">2018-10-20</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      线型回归 &amp; 梯度下降
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a><a class="article-category-link" href="/categories/机器学习/基础内容/">基础内容</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/梯度下降/">梯度下降</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="1-模型表示"><a href="#1-模型表示" class="headerlink" title="1.模型表示"></a>1.模型表示</h2><h3 id="问题的概述"><a href="#问题的概述" class="headerlink" title="问题的概述"></a><strong>问题的概述</strong></h3><blockquote>
<p>在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子。</p>
</blockquote>
<a id="more"></a>
<p><img src="/img/1539965168129.png" alt="1539965168129"></p>
<h3 id="模型引入"><a href="#模型引入" class="headerlink" title="模型引入"></a><strong>模型引入</strong></h3><p>假使我们回归问题的训练集（Training Set）如下表所示：</p>
<p><img src="/img/1539965299259.png" alt="1539965299259"></p>
<blockquote>
<p>我们将要用来描述这个回归问题的标记如下:<br>m 代表训练集中实例的数量<br>x 代表特征/输入变量<br>y 代表目标变量/输出变量<br>(x, y) 代表训练集中的实例<br>(x^i, y^i)代 表第 个观察实例<br>h 代表学习算法的解决方案或函数也称为假设（hypothesis）</p>
</blockquote>
<p><img src="/img/1539965543172.png" alt="1539965543172"></p>
<blockquote>
<p>这就是一个监督学习算法的工作方式，我们可以看到这里有我们的训练集里房屋价格 我们把它喂给我们的学习算法，学习算法的工作了，然后输出一个函数，通常表示为小写h表示。 h代表hypothesis(假设)， 表h示一个函数，输入是房屋尺寸大小，就像你朋友想出售的房屋，因此 h根据输入的 值来得出 y 值， y 值对应房子的价格因此， h 是一个从 x 到 y 的函数映射。</p>
<p>我将选择最初的使用规则代表hypothesis，因而，要解决房价预测问题，我们实际上是要将训练集“喂”给我们的学习算法，进而学习得到一个假设h，然后将我们要预测的房屋的尺寸作为输入变量输入给h，预测出该房屋的交易价格作为输出变量输出为结果。那么，对于我们的房价预测问题，我们该如何表达 h？一种可能的表达方式为：<strong>hθ(x)=θ0+θ1∗x</strong> ，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。</p>
</blockquote>
<h2 id="2-代价函数"><a href="#2-代价函数" class="headerlink" title="2.代价函数"></a>2.代价函数</h2><h3 id="什么是代价函数"><a href="#什么是代价函数" class="headerlink" title="什么是代价函数"></a>什么是代价函数</h3><p><img src="/img/1539965938888.png" alt="1539965938888"></p>
<p>在线性回归中我们有一个像这样的训练集， m代表了训练样本的数量 。而我们的假设函数，也就是用来进行预测的函数，是这样的线性函数形式：<strong>hθ(x)=θ0+θ1∗x</strong>  。<br>我们通过训练获得的预测函数在预测时必然会和实际值有一些偏差，下面就给出了这部分预测偏差的定义</p>
<blockquote>
<p><strong>代价函数的定义</strong>: 我们选择的参数决定了我们得到的模型相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是<strong>建模误差（modeling error）</strong>,下图蓝色线段变为预测和实际的误差。</p>
<p><strong>平方误差代价函数</strong>: 代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。</p>
</blockquote>
<p><img src="/img/1540021643524.png" alt="1540021643524"></p>
<h3 id="怎么优化线型回归模型"><a href="#怎么优化线型回归模型" class="headerlink" title="怎么优化线型回归模型"></a>怎么优化线型回归模型</h3><blockquote>
<p>优化回归模型的目标: 便是选择出可以使得建模误差的平方和能够最小的模型参数。 即使得代价函数最小。</p>
</blockquote>
<blockquote>
<p>代价函数公式:</p>
<p><img src="/img/1540029941521.png" alt="1540029941521"></p>
</blockquote>
<h3 id="代价函数坐标图"><a href="#代价函数坐标图" class="headerlink" title="代价函数坐标图"></a>代价函数坐标图</h3><p><img src="/img/1540022174651.png" alt="1540022174651"></p>
<blockquote>
<p>可以看出在三维空间中存在一个使得J(θ_0,θ_1)代价函数最小的点， 当代价函数取得最小值的时候，我们会获得最符合训练集的预测模型。</p>
</blockquote>
<h2 id="3-梯度下降算法"><a href="#3-梯度下降算法" class="headerlink" title="3.梯度下降算法"></a>3.梯度下降算法</h2><h3 id="算法介绍"><a href="#算法介绍" class="headerlink" title="算法介绍"></a>算法介绍</h3><blockquote>
<p>梯度下降是一个用来求函数最小值的算法。其思想是利用迭代的思想来逼近最低点，沿着梯度的负方向更新模型权重。我们将使用梯度下降算法来求出代价函数 J(θ_0,θ_1) 的最小值。</p>
</blockquote>
<blockquote>
<p>梯度下降背后的思想是：开始时我们随机选择一个参数的组合（θ0, θ1, …., θn），计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到找到一个局部最小值（local minimum），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（globalminimum），选择不同的初始参数组合，可能会找到不同的<strong>局部最小值</strong>。</p>
</blockquote>
<p><img src="/img/1540024168426.png" alt="1540024168426"></p>
<h3 id="梯度下降算法公式"><a href="#梯度下降算法公式" class="headerlink" title="梯度下降算法公式:"></a>梯度下降算法公式:</h3><p><strong>公式介绍</strong></p>
<p>repeat until convergence{<br>$$<br>θ_j=θ_j−α∂/∂θ_j J(θ0,θ1)　(for　j=0　and　j=1)<br>$$<br>}</p>
<p><img src="/img/1540026766508.png" alt="1540026766508"></p>
<blockquote>
<p>参数α: 学习率, 它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。当到达损失函数的最低点的时候，其导数为0，已经到达了局部最优点，即θ不会再发生改变</p>
</blockquote>
<blockquote>
<p>注意:  在梯度下降算法中，一般都会采用同步更新的方式来优化模型, 即上面公式的θj同步更新。同步更新是梯度下降中的一种常用方法。我们之后会讲到，同步更新是更自然的实现方法。当人们谈到梯度下降时，他们的意思就是同步更新。</p>
</blockquote>
<p><strong>学习率的选择对算法的影响</strong></p>
<ul>
<li><p>学习率过小的影响: 则达到收敛所需的迭代次数会非常高</p>
</li>
<li><p>学习率过大的影响: 每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛</p>
</li>
</ul>
<p><strong>怎么确定模型是否收敛</strong></p>
<p><img src="/img/1540568088758.png" alt="1540568088758"></p>
<ul>
<li><p>梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛, 如上图在300步之后基本接近收敛。</p>
</li>
<li><p>也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较</p>
</li>
</ul>
<h3 id="梯度下降算法分类"><a href="#梯度下降算法分类" class="headerlink" title="梯度下降算法分类"></a>梯度下降算法分类</h3><h4 id="批量梯度下降"><a href="#批量梯度下降" class="headerlink" title="批量梯度下降"></a><strong>批量梯度下降</strong></h4><blockquote>
<p>在上面的线性回归场景中的梯度下降算法，有时也称为批量梯度下降。实际上，在机器学习中，通常不太会给算法起名字，但这个名字”批量梯度下降”，指的是在梯度下降的每一步中，我们都用到了所有的训练样本，在梯度下降中，在计算微分求导项时，我们需要进行求和运算，所以，在每一个单独的梯度下降中，我们最终都要计算这样一个东西，这个项需要对所有m个训练样本求和。</p>
</blockquote>
<blockquote>
<p>批量梯度下降法这个名字说明了我们需要考虑所有这一”批”训练样本，而事实上，有时也有其他类型的梯度下降法，不是这种”批量”型的，不考虑整个的训练集，而是每次只关注训练集中的一些小的子集。</p>
</blockquote>
<p><strong>优点：</strong><br>  （1）一次迭代是对所有样本进行计算，此时利用矩阵进行操作，实现了并行。<br>  （2）由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。当目标函数为凸函数时，BGD一定能够得到全局最优。</p>
<p><strong>缺点：</strong><br>  （1）当样本数目 m 很大时，每迭代一步都需要对所有样本计算，训练过程会很慢。</p>
<h4 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a><strong>随机梯度下降</strong></h4><p>公式: <img src="/img/1540042706219.png" alt="1540042706219"></p>
<blockquote>
<p>随机梯度下降指在梯度下降的每一步中只用到了训练集的一个样本或者一部分样本，最后得到的可能是全局最优解，也可能是局部最优解。</p>
</blockquote>
<p><strong>优点：</strong><br>  （1）由于不是在全部训练数据上的损失函数，而是在每轮迭代中，随机优化某一条训练数据上的损失函数，这样每一轮参数的更新速度大大加快。<br><strong>缺点：</strong><br>  （1）准确度下降。由于即使在目标函数为强凸函数的情况下，SGD仍旧无法做到线性收敛。<br>  （2）可能会收敛到局部最优，由于单个样本并不能代表全体样本的趋势。<br>  （3）不易于并行实现。</p>
<h2 id="4-梯度下降线型回归模型"><a href="#4-梯度下降线型回归模型" class="headerlink" title="4.梯度下降线型回归模型"></a>4.梯度下降线型回归模型</h2><h3 id="单变量线型回归梯度下降"><a href="#单变量线型回归梯度下降" class="headerlink" title="单变量线型回归梯度下降"></a>单变量线型回归梯度下降</h3><h4 id="梯度下降、线型回归算法比较"><a href="#梯度下降、线型回归算法比较" class="headerlink" title="梯度下降、线型回归算法比较"></a><strong>梯度下降、线型回归算法比较</strong></h4><p><img src="/img/1540028773553.png" alt="1540028773553"></p>
<h4 id="单变量梯度下降公式"><a href="#单变量梯度下降公式" class="headerlink" title="单变量梯度下降公式"></a>单变量梯度下降公式</h4><p><strong>代价函数计算</strong></p>
<p><img src="/img/1540028837422.png" alt="1540028837422"></p>
<p><strong>参数θ的计算</strong></p>
<p><img src="/img/1540028905489.png" alt="1540028905489"></p>
<h3 id="多变量线型回归梯度下降"><a href="#多变量线型回归梯度下降" class="headerlink" title="多变量线型回归梯度下降"></a>多变量线型回归梯度下降</h3><h4 id="多变量特征"><a href="#多变量特征" class="headerlink" title="多变量特征"></a>多变量特征</h4><p>现在对回归模型增加更多的特征，例如房价预测问题，增加房间数楼层等，构成一个含有多个变量的模型，模型中的特征如下图。</p>
<p><img src="/img/1540563412916.png" alt="1540563412916"></p>
<p><strong>增添更多特征后，引入一系列新的注释</strong>：</p>
<blockquote>
<ul>
<li><p>n 代表特征的数量</p>
</li>
<li><p>x^(i)^ 代表第i个训练实例，是特征矩阵的第i行，是一个向量(vector).</p>
</li>
<li><p>x~j~^(i)^ 代表特征矩阵中第i行的第j个特征，也就是第i个训练实例的第j个特征  如:  $x_2^{(2)} = 3, x_3^{(2)} = 2$</p>
</li>
<li><p>支持多个变量的h表示为: $h_θ(x) = θ_0 + θ_1x_1 + θ_2x_2 + … + θ_nx_n$</p>
<ul>
<li>这个公式中有个n+1参数和n个变量，为了使得公式能够简化一些，引入$x_0=1$，则公式转化为:$h_θ(x) = θ_0x_0 + θ_1x_1 + θ_2x_2 + … + θ_nx_n$</li>
</ul>
</li>
<li><p>此时模型中的参数是一个n+1维的向量，任何一个训练实例也都是n+1维的向量，特征矩阵X的维度是m* (n+1),</p>
<p>因此变量的假设公式可以表示为: $h_θ(x) = θ^TX$</p>
</li>
</ul>
</blockquote>
<h4 id="多变量梯度下降公式"><a href="#多变量梯度下降公式" class="headerlink" title="多变量梯度下降公式"></a>多变量梯度下降公式</h4><p>与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：</p>
<p>$J_{(θ_0, .., θ<em>n)} = {1\over2m}\sum</em>{i=1}^m(h_θ(x^{(i)}) - y^{(i)})^2 , 其中: h_θ(x) = θ^TX = θ_0x_0 + θ_1x_1 + θ_2x_2 + … + θ_nx_n$<img src="/img/1540635502085.png" alt="1540635502085"></p>
<p>我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。 多变量线性回归的批量梯度<br><strong>梯度下降下降公式：</strong></p>
<p><img src="/img/1540566461561.png" alt="1540566461561"></p>
<p><strong>求导数后得到:</strong></p>
<p><img src="/img/1540566614915.png" alt="1540566614915"></p>
<h3 id="5-特征和多项式回归"><a href="#5-特征和多项式回归" class="headerlink" title="5.特征和多项式回归"></a>5.特征和多项式回归</h3><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a><strong>特征选择</strong></h3><blockquote>
<p>有的时候的们的特征并不是很好的可以直接用来训练模型，比如房子价格预测模型的两个特征</p>
<p>特征: x1 房子的临街宽度， x2 房子的纵向深度</p>
<p>此时很明显房子的价格用 特征一和特征二的乘积，即房子的占地面积来预测更合适  $x=x_1 * x_2 = area (面积)$</p>
</blockquote>
<p><img src="/img/1540616820528.png" alt="1540616820528"></p>
<h3 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a><strong>多项式回归</strong></h3><blockquote>
<p>很多时候，我们并没有那么幸运，正好所有的数据之间都是线性关系，能用一条直线，一个平面就描述地出来，大多数时候，我们可能需要画成曲线、曲面或者曲啥更高维度的东西</p>
<p>比如下图数据集，线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，用二次方程（蓝色的线）和三次方程（绿色的线）来拟合这些点，但是二次方程有个缺点，到了后面，反而会下降，这和我们的认知不符合，而三次方程不会遇到这个问题，和二次方程相加又会和上升的部分相互抵消一部分，所以最后选择了三次方程加上二次方程。</p>
<p>二次方模型公式：$h_θ(x) = θ_0 + θ_1x_1 + θ_2x_2^2$      三次方模型公式: $h_θ(x) = θ_0 + θ_1x_1 + θ_2x_2^2 + θ_3x_3^3$ </p>
</blockquote>
<p><img src="/img/1540616493267.png" alt="1540616493267"></p>
<blockquote>
<p>通常我们需要先观察数据然后再决定准备尝试怎样的模型。 另外，我们可以把多项式回归看成是另类的多变量线性回归，我们可以令：$x_2 = x_2^2$ , $x_3 = x_3^3$ , 从而将模型转化为线型回归模型</p>
<p>注：如果我们采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要, 因为比如x的范围是1-100的话，$x^2$的范围就是1-10000，$x^3$的范围就是1-1000000。</p>
</blockquote>
<h2 id="6-特征缩放"><a href="#6-特征缩放" class="headerlink" title="6.特征缩放"></a>6.特征缩放</h2><h3 id="为什么要特征缩放"><a href="#为什么要特征缩放" class="headerlink" title="为什么要特征缩放"></a>为什么要特征缩放</h3><blockquote>
<p>在使用梯度下降的时候会遇到因为特征大小不统一，导致收敛速度过慢的问题，在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。</p>
</blockquote>
<p>以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。</p>
<p><img src="/img/1540567672941.png" alt="1540567672941"></p>
<blockquote>
<p>解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。</p>
</blockquote>
<h3 id="特征缩放的两种方法"><a href="#特征缩放的两种方法" class="headerlink" title="特征缩放的两种方法"></a>特征缩放的两种方法</h3><p><strong>线型归一化</strong></p>
<ul>
<li><p>原理： </p>
</li>
<li><ul>
<li>通过对原始数据进行变换把数据映射到(默认为[0,1])之间</li>
</ul>
</li>
<li><p>公式</p>
</li>
<li><ul>
<li><img src="/img/1540644955305.png" alt="1540644955305"></li>
</ul>
</li>
<li><p>归一化的弊端</p>
</li>
<li><ul>
<li>使用归一化的时候，最大值和最小值非常容易受到异常点的影响， 所以这种只适合于传统精确小的数据场景</li>
</ul>
</li>
</ul>
<p><strong>特征标准化</strong></p>
<ul>
<li><p>原理：</p>
<ul>
<li>通过对原始数据进行变换把数据变换到均值为0,方差为1的正太分布范围内</li>
</ul>
</li>
<li><p>公式：</p>
<ul>
<li><img src="/img/1540645069496.png" alt="1540645069496"></li>
</ul>
</li>
<li>标准化的有点<ul>
<li>如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小, 对标准化的影响较小。</li>
</ul>
</li>
</ul>
<h2 id="7-正规方程线型回归"><a href="#7-正规方程线型回归" class="headerlink" title="7.正规方程线型回归"></a>7.正规方程线型回归</h2><h3 id="正规方程算法介绍"><a href="#正规方程算法介绍" class="headerlink" title="正规方程算法介绍"></a>正规方程算法介绍</h3><blockquote>
<p>对于线型回归问题经常都是在使用梯度下降算法，但是对于某些线型回归问题，正规方程是更好的解决办法。如下面的代价函数:</p>
</blockquote>
<p><img src="/img/1540619927547.png" alt="1540619927547"></p>
<p><img src="/img/1540620250525.png" alt="1540620250525"></p>
<h3 id="梯度下降和正规方程比较"><a href="#梯度下降和正规方程比较" class="headerlink" title="梯度下降和正规方程比较"></a>梯度下降和正规方程比较</h3><table>
<thead>
<tr>
<th>梯度下降</th>
<th>正规方程</th>
</tr>
</thead>
<tbody>
<tr>
<td>需要选择学习率</td>
<td>不需要</td>
</tr>
<tr>
<td>需要多次迭代</td>
<td>一次运算得出</td>
</tr>
<tr>
<td>当特征数量n特别大时能比较适用</td>
<td>需要计算$(X^TX)^{-1}$如果特征数量n较大则运算代价大因为矩阵逆的计算时间复杂度为$O(n^3)$，通常来说当小于10000 时还是可以接受</td>
</tr>
<tr>
<td>适用于各种类型的模型</td>
<td>只适用于线性模型，不适合逻辑回归模型等其他模型</td>
</tr>
</tbody>
</table>
<blockquote>
<p>总结一下，只要特征变量的数目并不大，标准方程是一个很好的计算参数的替代方法。具体地说，只要特征变量数量小于一万，我通常使用标准方程法，而不使用梯度下降法。</p>
</blockquote>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2018/10/20/10.机器学习/基础内容/线型回归/">线型回归 &amp; 梯度下降</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">刘小恺</a></p>
        <p><span>发布时间:</span>2018-10-20, 00:01:00</p>
        <p><span>最后更新:</span>2018-10-28, 19:43:48</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2018/10/20/10.机器学习/基础内容/线型回归/" title="线型回归 &amp; 梯度下降">http://blog.kyleliu.cn/2018/10/20/10.机器学习/基础内容/线型回归/</a>
            <span class="copy-path" data-clipboard-text="原文: http://blog.kyleliu.cn/2018/10/20/10.机器学习/基础内容/线型回归/　　作者: 刘小恺" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2018/10/26/10.机器学习/基础内容/octave 基础操作/">
                    Octave基础操作
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2018/10/19/10.机器学习/基础内容/机器学习介绍/">
                    机器学习介绍
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-模型表示"><span class="toc-number">1.</span> <span class="toc-text">1.模型表示</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#问题的概述"><span class="toc-number">1.1.</span> <span class="toc-text">问题的概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型引入"><span class="toc-number">1.2.</span> <span class="toc-text">模型引入</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-代价函数"><span class="toc-number">2.</span> <span class="toc-text">2.代价函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是代价函数"><span class="toc-number">2.1.</span> <span class="toc-text">什么是代价函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#怎么优化线型回归模型"><span class="toc-number">2.2.</span> <span class="toc-text">怎么优化线型回归模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#代价函数坐标图"><span class="toc-number">2.3.</span> <span class="toc-text">代价函数坐标图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-梯度下降算法"><span class="toc-number">3.</span> <span class="toc-text">3.梯度下降算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#算法介绍"><span class="toc-number">3.1.</span> <span class="toc-text">算法介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#梯度下降算法公式"><span class="toc-number">3.2.</span> <span class="toc-text">梯度下降算法公式:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#梯度下降算法分类"><span class="toc-number">3.3.</span> <span class="toc-text">梯度下降算法分类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#批量梯度下降"><span class="toc-number">3.3.1.</span> <span class="toc-text">批量梯度下降</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#随机梯度下降"><span class="toc-number">3.3.2.</span> <span class="toc-text">随机梯度下降</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-梯度下降线型回归模型"><span class="toc-number">4.</span> <span class="toc-text">4.梯度下降线型回归模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#单变量线型回归梯度下降"><span class="toc-number">4.1.</span> <span class="toc-text">单变量线型回归梯度下降</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#梯度下降、线型回归算法比较"><span class="toc-number">4.1.1.</span> <span class="toc-text">梯度下降、线型回归算法比较</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#单变量梯度下降公式"><span class="toc-number">4.1.2.</span> <span class="toc-text">单变量梯度下降公式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多变量线型回归梯度下降"><span class="toc-number">4.2.</span> <span class="toc-text">多变量线型回归梯度下降</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#多变量特征"><span class="toc-number">4.2.1.</span> <span class="toc-text">多变量特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#多变量梯度下降公式"><span class="toc-number">4.2.2.</span> <span class="toc-text">多变量梯度下降公式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-特征和多项式回归"><span class="toc-number">4.3.</span> <span class="toc-text">5.特征和多项式回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征选择"><span class="toc-number">4.4.</span> <span class="toc-text">特征选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多项式回归"><span class="toc-number">4.5.</span> <span class="toc-text">多项式回归</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-特征缩放"><span class="toc-number">5.</span> <span class="toc-text">6.特征缩放</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么要特征缩放"><span class="toc-number">5.1.</span> <span class="toc-text">为什么要特征缩放</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征缩放的两种方法"><span class="toc-number">5.2.</span> <span class="toc-text">特征缩放的两种方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-正规方程线型回归"><span class="toc-number">6.</span> <span class="toc-text">7.正规方程线型回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#正规方程算法介绍"><span class="toc-number">6.1.</span> <span class="toc-text">正规方程算法介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#梯度下降和正规方程比较"><span class="toc-number">6.2.</span> <span class="toc-text">梯度下降和正规方程比较</span></a></li></ol></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"线型回归 & 梯度下降　| 刘小恺(Kyle) 的个人博客　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2018/10/26/10.机器学习/基础内容/octave 基础操作/" title="上一篇: Octave基础操作">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2018/10/19/10.机器学习/基础内容/机器学习介绍/" title="下一篇: 机器学习介绍">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/10/26/10.机器学习/基础内容/octave 基础操作/">Octave基础操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/20/10.机器学习/基础内容/线型回归/">线型回归 & 梯度下降</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/19/10.机器学习/基础内容/机器学习介绍/">机器学习介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/scrapy框架/数据格式化输出/">4.python爬虫/scrapy框架/数据格式化输出</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/scrapy框架/Scrapy框架介绍/">4.python爬虫/scrapy框架/Scrapy框架介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/scrapy框架/scrapy对接splash/">4.python爬虫/scrapy框架/scrapy对接splash</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/scrapy框架/scrapy_redis框架/">4.python爬虫/scrapy框架/scrapy_redis框架</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/scrapy框架/scrapyd部署总结/">4.python爬虫/scrapy框架/scrapyd部署总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/scrapy框架/Scrapy-settinglog信息/">4.python爬虫/scrapy框架/Scrapy-settinglog信息</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/scrapy框架/Scrapy-pipeline/">4.python爬虫/scrapy框架/Scrapy-pipeline</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/scrapy框架/Scrapy-middleware/">4.python爬虫/scrapy框架/Scrapy-middleware</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/scrapy框架/Scrapy-items&spider/">4.python爬虫/scrapy框架/Scrapy-items&spider</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/scrapy框架/Gerapy的介绍/">4.python爬虫/scrapy框架/Gerapy的介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫基础/网络爬虫介绍/">4.python爬虫/爬虫基础/网络爬虫介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫基础/爬虫相关工具列表/">4.python爬虫/爬虫基础/爬虫相关工具列表</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫基础/正则表达式/">4.python爬虫/爬虫基础/正则表达式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫基础/数据提取 json  Xpath/">4.python爬虫/爬虫基础/数据提取 json  Xpath</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫基础/多线程爬虫/">4.python爬虫/爬虫基础/多线程爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫基础/Splash动态爬取/">4.python爬虫/爬虫基础/Splash动态爬取</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫基础/Selenium动态爬取/">4.python爬虫/爬虫基础/Selenium动态爬取</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫基础/Request模块使用/">4.python爬虫/爬虫基础/Request模块使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫基础/Puppeteer动态爬取/">4.python爬虫/爬虫基础/Puppeteer动态爬取</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫扩展功能/数据快速写入Csv文件/">4.python爬虫/爬虫扩展功能/数据快速写入Csv文件</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫扩展功能/数据去重方法-HashBloom/">4.python爬虫/爬虫扩展功能/数据去重方法-HashBloom</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫扩展功能/mitmproxy&mitmdump手机爬虫/">4.python爬虫/爬虫扩展功能/mitmproxy&mitmdump手机爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫扩展功能/Fiddler抓包工具安装、配置/">4.python爬虫/爬虫扩展功能/Fiddler抓包工具安装、配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫扩展功能/Fiddler在ios上配置/">4.python爬虫/爬虫扩展功能/Fiddler在ios上配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫扩展功能/Fiddler在Android上配置/">4.python爬虫/爬虫扩展功能/Fiddler在Android上配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫扩展功能/Crontab定时执行爬虫/">4.python爬虫/爬虫扩展功能/Crontab定时执行爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫扩展功能/Charles抓包工具安装、配置/">4.python爬虫/爬虫扩展功能/Charles抓包工具安装、配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫扩展功能/Appium手机爬虫/">4.python爬虫/爬虫扩展功能/Appium手机爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫特殊反反爬/破解诡异字体/">4.python爬虫/爬虫特殊反反爬/破解诡异字体</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫特殊反反爬/参数伪造/">4.python爬虫/爬虫特殊反反爬/参数伪造</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫特殊反反爬/CssContent字体破解/">4.python爬虫/爬虫特殊反反爬/CssContent字体破解</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫特殊反反爬/CloudFlare邮箱加密(cfemail)/">4.python爬虫/爬虫特殊反反爬/CloudFlare邮箱加密(cfemail)</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/celery分布式爬虫/分布式任务队列Celery/">4.python爬虫/celery分布式爬虫/分布式任务队列Celery</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/celery分布式爬虫/Celery构建一个分布式爬虫：理论篇/">4.python爬虫/celery分布式爬虫/Celery构建一个分布式爬虫：理论篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/celery分布式爬虫/Celery构建一个分布式爬虫：基础篇/">4.python爬虫/celery分布式爬虫/Celery构建一个分布式爬虫：基础篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/celery分布式爬虫/celery分布式：监控界面/">4.python爬虫/celery分布式爬虫/celery分布式：监控界面</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/celery分布式爬虫/Celery&flower 后台运行部署/">4.python爬虫/celery分布式爬虫/Celery&flower 后台运行部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫常见反反爬/滑动验证码识别/">4.python爬虫/爬虫常见反反爬/滑动验证码识别</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫常见反反爬/图片验证码-Tesseract破解/">4.python爬虫/爬虫常见反反爬/图片验证码-Tesseract破解</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫常见反反爬/代理池的搭建/">4.python爬虫/爬虫常见反反爬/代理池的搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫常见反反爬/Js压缩、混淆、加密及破解/">4.python爬虫/爬虫常见反反爬/Js压缩、混淆、加密及破解</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/18/4.python爬虫/爬虫常见反反爬/ADSL代理服务器搭建&代理池/">4.python爬虫/爬虫常见反反爬/ADSL代理服务器搭建&代理池</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/17/20.开发工具/博客/github+hexo博客搭建/">githubpage + hexo + yilia 搭建个人博客</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/17/11.Docker容器技术/Docker/搭建Registry私有库/">搭建Registry 私有库</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2016-2018 刘小恺
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>